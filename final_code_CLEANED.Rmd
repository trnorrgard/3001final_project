---
title: "Airbnb Questions"
author: "Akhil Havaldar, Teagan Norrgard, Ronica Peraka"
date: "12/8/2021"
output: 
  html_document:
    toc: TRUE
    theme: readable
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---
```{r, warning=FALSE, include=FALSE}
### Reading in the packages
library(dplyr)
library(tidyverse)
library(e1071)
library(magrittr)
library(lubridate)
library(data.table)
library(ggrepel)
library(ggmap)
library(ggplot2)
library(plotly)
library(htmltools)
library(caret)
library(class)
library(devtools)
library(NbClust)
library(data.table)
library(ROCR)
library(mltools)
library(MLmetrics)
```

### Clusters: Question #1

Our dataset was obtained from Kaggle but the data itself was sourced from Inside Airbnb. It contains information about the different Airbnb listings from 2016 in Boston with information about the names, locations, and other descriptors of the different properties. With our data, we wanted to examine the relationship between the price of Airbnb properties, and the neighborhood it is listed in. More specifically, we wanted to see if our model could predict a neighborhood based off of price and other variables. We thought this would be an interesting dataset to explore with the growth of the tourism industry as vaccination rates rise and cities start to open up. We cleaned the data by cutting down the dataset to the relevant information, handling the NA values, and factoring certain variables. Through our exploration and modeling, we determined which variables we thought would be the best predictors of neighborhoods. Using visualization, we then used KNN clustering to predict neighborhood groups. 

For a second question, we also wanted to explore how different Airbnb listings got rated by people who stayed there. We looked into how different variables influenced rating as a way to predict whether a person would enjoy their stay at an Airbnb, since rating can be an indicator of if a person had a good experience there. We thought this would be a good addition to our project, since both price and the rating of a place impact if one would book an Airbnb. If the price of the neighboorhood area was low, but the rating was also low, a person may be less likely to choose it. We want to find a way to find a good deal with price with a high rating. We used kNN and evaluated with confusion matrix, logloss, F1, and ROC. 


```{r, include=FALSE}
boston <- read.csv("Boston_Airbnb_copy.csv")
```

```{r, include=FALSE}
boston <- boston%>%
  select(c("name","neighbourhood_cleansed","latitude", "longitude", "room_type", 
           "accommodates", "price", "review_scores_rating", 
           "host_is_superhost", "property_type"))
boston <-  boston%>%
  rename(superhost = host_is_superhost, neighborhood = neighbourhood_cleansed)
boston$price = as.numeric(gsub("\\$", "", boston$price))    #data cleaning
```

### Clusters: Exploratory Data Analysis
Here we looked at neighborhood counts, and saw that the most popular neighborhoods are Jamaica Plain, South End, Back Bay, Fenway, Dorchester, and Allston.
```{r, echo=FALSE}
table(boston$neighborhood)  #25 neighborhoods
```

#### Median Values Grouped by Neighborhood
```{r, echo=FALSE}
## could be interesting to compare to means of the reviews and prices
bost_med_table <- boston%>%
  group_by(neighborhood)%>%
  summarise(medianReview = median(review_scores_rating, na.rm=T),
            medianPrice = median(price, na.rm=T))
bost_med_table
```

#### Median Prices by Neighborhood
```{r, echo=FALSE}
plot <- ggplot(data=bost_med_table, aes(x=neighborhood, y=medianPrice, fill=medianPrice))+
  scale_fill_gradient(low = "dark red", high = "cornflowerblue")+
  geom_bar(stat='identity')+
  theme(axis.text.x = element_text(angle=90))+
  labs(x="Neighborhood", y="Median Price of Airbnb per Night", title="Distribution of Airbnb prices per night over Neighborhoods in Boston")
plot    #visually see which neighborhoods had the highest and lowest prices
```

#### Room Type by Neighborhood
```{r, echo=FALSE, warning=FALSE, message=FALSE}
#room types include home/apt, private room, and shared room
boston%>%
  group_by(neighborhood)%>%
  select(room_type)%>%
  table()
```

#### Top 100 Most Expensive, by Neighborhood
We see here that the top 100 most expensive Airbnbs are pretty evenly distributed over the neighborhoods. Back Bay has the highest number with 17 but doesn't seem so high that it is an outlier. This also makes sense because Back Bay was one of the most popular neighborhoods in the first place.
```{r, echo=FALSE}
boston_top100 <- boston%>%
  arrange(desc(price))
head(boston_top100, 100)%>%
  select(neighborhood)%>%
  table()
```

### Clustering Model
First we picked which variables we thought would do the best at predicting neighborhoods. We chose to use price and rating, and room type since that is where we saw the greatest variation by neighborhood in our exploration.
```{r, include=FALSE}
clust_boston <- boston[, c("price", "review_scores_rating", "room_type")]
```

```{r, include=FALSE, warning=FALSE}
table(clust_boston$room_type)
clust_boston$room_type <- fct_collapse(clust_boston$room_type,
                                  v1 = "Entire home/apt",
                                  v2 = "Private room",
                                  v3 = "Shared room")
clust_boston$room_type = as.numeric(gsub("v", "", clust_boston$room_type))    #labeled room type by numbers
```

```{r, include=FALSE}
#replacing NA values by the median since there were very few NA values
clust_boston$review_scores_rating[is.na(clust_boston$review_scores_rating)] <- median(clust_boston$review_scores_rating, na.rm=T)
clust_boston$price[is.na(clust_boston$price)] <- median(clust_boston$price, na.rm=T)
sum(is.na(clust_boston$review_scores_rating))
sum(is.na(clust_boston$price))
```

```{r, include=FALSE}
normalize <- function(x){
 (x - min(x)) / (max(x) - min(x))
}
clust_boston[1:2] <- lapply(clust_boston[1:2], normalize)
```

```{r, include=FALSE}
# Then we sorted the neighborhoods into 2 groups, central Boston and Boston suburbs.

boston$neighborhood_groups <- fct_collapse(boston$neighborhood,
                                           Suburbs = c("Jamaica Plain", "Roslindale", 
                                                       "Dorchester","Roxbury", 
                                                       "West Roxbury", "Hyde Park", 
                                                       "Mattapan", "Brighton", "Allston"),
                                           Central_Boston = c("Bay Village", "Back Bay",
                                                              "Beacon Hill", "West End",
                                                              "North End", "Downtown",
                                                              "South End", "Chinatown",
                                                              "Leather District", "Fenway", 
                                                              "Mission Hill", "Longwood Medical Area", 
                                                              "South Boston", "South Boston Waterfront", 
                                                              "Charlestown", "East Boston"))
```

#### Elbow Method
Based on this graph, it looks like 2 clusters will give us the best model without over-fitting. This also makes sense because we collapsed the neighborhoods into 2 groups.

```{r, warning=FALSE, echo=FALSE}
explained_variance = function(data_in, k){
  set.seed(1)
  kmeans_obj = kmeans(data_in, centers = k, algorithm = "Lloyd", iter.max = 30)
  var_exp = kmeans_obj$betweenss / kmeans_obj$totss
  var_exp  
}
explained_var_boston = sapply(1:10, explained_variance, data_in = clust_boston)

elbow_boston = data.frame(k = 1:10, explained_var_boston)
ggplot(elbow_boston, 
       aes(x = k,  
           y = explained_var_boston)) + 
  geom_point(size = 4) +
  geom_line(size = 1) + 
  xlab('k') + 
  ylab('Inter-cluster Variance / Total Variance') + 
  theme_light()
```

```{r, warning=FALSE, include=FALSE}
#kmeans
set.seed(1)
kmeans_obj_boston = kmeans(clust_boston, centers = 2, 
                        algorithm = "Lloyd")
kmeans_obj_boston
clusters_boston = as.factor(kmeans_obj_boston$cluster)
```

### Clusters: Visualizations
#### Scatterplot
```{r, warning=FALSE, echo=FALSE}
#visually see how clustering model predicts the neighborhood groups, Suburb or Central
neighborhood_clusters = as.factor(kmeans_obj_boston$cluster)
ggplot(boston, aes(x = price, 
                            y = review_scores_rating,
                            color = neighborhood_groups,
                            shape = neighborhood_clusters)) + 
  geom_point(size = 2) +
  ggtitle("Price vs Rating of Boston Airbnbs") +
  xlab("Price per Night") +
  ylab("Review Score (out of 100)") +
  scale_shape_manual(name = "Cluster", 
                     labels = c("Cluster 1", "Cluster 2"),
                     values = c("1", "2")) +
  theme_light()
```

#### Map of Airbnbs and Their Clusters
We thought a map where you could see the physical location of the properties would be the best way to visualize our model, so we appended the clusters to our dataset and installed the required packages.
```{r, include=FALSE}
boston$clusters <- neighborhood_clusters
```

```{r, include=FALSE, warning=FALSE, echo=FALSE, message=FALSE}
#importing Google maps
if(!requireNamespace("devtools")) install.packages("devtools")
devtools::install_github("dkahle/ggmap", ref = "tidyup", force=TRUE)
library('ggmap')
 
ggmap::register_google(key = 'AIzaSyBYxfE_HmtWRQ-YgKd4I7-QZ-fI0AzP4zQ')
```

Since this map is not interactive, we adjusted the center of the map to fit all of the properties and zoomed as far as we could without Airbnbs  getting cut off. Here, of the 3585 observations, only 5 did not fit in the map.
```{r, message=FALSE, echo=FALSE, warning=FALSE}
#can visually see where the locations of the neighbohoods are on a map of Boston
map1 <- ggmap(get_googlemap(center = c(lon = -71.0759, lat = 42.319),
                    zoom = 12, scale = 2,
                    maptype ='terrain',
                    color = 'color'))+ 
  geom_point(aes(x = longitude, y = latitude,  colour = clusters), data = boston, size = 0.5) + 
  theme(legend.position="bottom")
map1
```

We ran the map again, this time zooming in on central Boston to get a clearer look at it. Only 1747 properties are shown in this map, but we see here that our model is doing a pretty good job at predicting Airbnbs in Central Boston.
```{r, message=FALSE, echo=FALSE, warning=FALSE}
map_zoomed <- ggmap(get_googlemap(center = c(lon = -71.0759, lat = 42.35101),
                    zoom = 14, scale = 2,
                    maptype ='terrain',
                    color = 'color'))+ 
  geom_point(aes(x = longitude, y = latitude,  colour = clusters), data = boston, size = 0.5) + 
  theme(legend.position="bottom")
map_zoomed
```

### Clusters: Counfusion Matrix

```{r, include=FALSE}
clust_boston$neighborhood_groups <- boston$neighborhood_groups
clust_boston$clusters <- neighborhood_clusters
clust_boston[,c(4,5)] <- lapply(clust_boston[,c(4,5)], as.factor)
```

```{r, include=FALSE}
#creating train, tune, and test sets
train_index <- createDataPartition(clust_boston$neighborhood_groups,
                                           p = .7,   #the train set is 70% of the data
                                           list = FALSE,
                                           times = 1)
train <- clust_boston[train_index,]
tune_and_test <- clust_boston[-train_index, ]
tune_and_test_index <- createDataPartition(tune_and_test$neighborhood_groups,
                                           p = .5,     #the tune and test sets will each be 15%
                                           list = FALSE,
                                           times = 1)
tune <- tune_and_test[tune_and_test_index, ]
test <- tune_and_test[-tune_and_test_index, ]
features <- as.data.frame(train[,-c(4)])
target <- train$neighborhood_groups
```

```{r, include=FALSE}
boston_dt <- train(x=features,
                    y=target,
                    method="rpart")
```

#### Variable Importance
```{r, echo=FALSE}
varImp(boston_dt)
#In order of importance: price, clusters, and room type, reviews
```

```{r, echo=FALSE}
dt_predict_1 = predict(boston_dt,tune,type= "raw")
confusionMatrix(as.factor(dt_predict_1), 
                as.factor(tune$neighborhood_groups), 
                dnn=c("Prediction", "Actual"), 
                mode = "sens_spec")
```

### Clusters: Conclusions

Our accuracy is 72% which isn't the best, but we think our model did a good job predicting the neighborhood with the information it was given. We think that if we could have included more information that was in our original dataset, such as amenities, parking availability, and transit information, our model could have likely been more accurate, and we could have even split up our neighborhood groups more. (Maybe groups of downtown, central, suburbs). Unfortunately these variables were in sentence format written by the host, and were difficult to sort through and use in our clustering model.

The variable importance output shows us that price was by far the most important variable for predicting neighborhood, which is the relationship we wanted to explore in the beginning. Using our map, we think our model is a valuable tool for finding Airbnbs that could be considered a good deal. Since price was used 100% of the time to predict our clusters, we can draw conclusions about the relative price of an Airbnb compared to the neighborhood it is in. Any Airbnb which was actually located in Central Boston but predicted as the Suburbs likely have a price much lower than other similar Airbnbs in Central Boston. The opposite is also true, where incorrectly classifies properties in the Suburbs are likely more expensive than others.


### KNN: Question #2
Based on the Airbnb data in Boston, we want to see which factors can predict if a renter will enjoy their stay or not. Some variables were price, room type, neighborhood, whether the host is a superhost, property type, and number of accomodates. Based on the distribution of reviews, we decided that most renters who enjoy their stay without complaints give a rating of 95+. A rating of 95+ will be used as the threshold for enjoying a stay. We decided on this question because a renter should be able to know if they will enjoy their stay before booking the property, otherwise it would be a waste of a trip. This should be something that is possible with the amount of information given for the listing, and the number of reviews each property receives. 

Through exploratory data analysis, we decided on which variables would be ideal to include in our model. We chose rating, price, room type, neighborhood, superhost status, property type, and accomodates. Through data cleaning and exploration, we determined that these variables would be best to predict if a person were to enjoy their stay at a property. These variables have been scaled if necessary, and factored into sufficient categories. Using KNN and evaluation techniques, we created a model to predict rating.

```{r, include=FALSE}
### Data cleaning
boston <- read_csv("Boston_Airbnb_copy.csv")
boston <- boston%>%
  select(c("neighbourhood_cleansed", "room_type", 
           "accommodates", "price", "review_scores_rating", 
           "host_is_superhost", "property_type"))
boston <-  boston%>%
  rename(superhost = host_is_superhost, neighborhood = neighbourhood_cleansed, rating=review_scores_rating)
boston$price = as.numeric(gsub("\\$", "", boston$price))

## Removing NA's
boston <- boston[complete.cases(boston),]

##Factor Collapsing each variable
boston$neighborhood <- fct_collapse(boston$neighborhood, 
                                    north = c("East Boston", "Charlestown", "Allston", "Brighton", "Fenway", "Back Bay", "Beacon Hill", "West End", "North End", "Chinatown", "Longwood Medical Area", "Bay Village", "Downtown"), south = c("South End", "South Boston", "Mission Hill", "West Roxbury", "Leather District", "Dorchester", "Mattapan", "Hyde Park", "Jamaica Plain", "Roslindale", "Roxbury", "South Boston Waterfront"))

boston$room_type <- as.factor(boston$room_type)

boston$rating <- ifelse(boston$rating < 95, "0", "1")   #values for high or low rating
boston$rating <- as.factor(boston$rating)

boston$superhost <- as.factor(boston$superhost)
boston$superhost <- recode(boston$superhost,
                       'FALSE'="no",'TRUE'="yes") 

boston$property_type <- fct_collapse(boston$property_type, 
                                     room = c("Dorm", "Loft"),
                                     partial_home = c("Guesthouse", "Entire Floor"),
                                     home = c("House", "Apartment", "Townhouse", "Villa", "Condominium"),
                                     other = c("Bed & Breakfast", "Boat", "Other"))

### Scaling the numeric values to match the scale
scaled_boston <- as.data.frame(scale(boston[3:4], center = TRUE, scale = TRUE))
boston <- boston[,-c(3,4)]

### New combined data set
boston <- cbind(scaled_boston, boston)
```

```{r, include=FALSE}
### Creating train, tune, and test sets
part_index_1 <- createDataPartition(boston$rating,
                                           times=1,
                                           p = 0.70,
                                           groups=1,
                                           list=FALSE)
train <- boston[part_index_1,]
tune_and_test <- boston[-part_index_1, ]
tune_and_test_index <- createDataPartition(tune_and_test$rating,
                                           p = .5,
                                           list = FALSE,
                                           times = 1)
tune <- tune_and_test[tune_and_test_index, ]
test <- tune_and_test[-tune_and_test_index, ]

#the train set will be 70% of the data and tune and test are 15% each
dim(train)
dim(tune)
dim(test)
```

### KNN Model

```{r, include=FALSE}
### Running knn
set.seed(123)
trctrl_1 <- trainControl(method = "repeatedcv",
                       number = 10,
                       repeats = 5)
boston_knn_1 <- train(rating~.,
                  data = train,
                  method="knn",
                  tuneLength=10,
                  trControl= trctrl_1,
                  preProcess="scale")

trctrl_2 <- trainControl(method = "repeatedcv",
                       number = 20,
                       repeats = 10)
boston_knn_2 <- train(rating~.,
                  data = train,
                  method="knn",
                  tuneLength=10,
                  trControl= trctrl_2,
                  preProcess="scale")

trctrl_3 <- trainControl(method = "repeatedcv",
                       number = 50,
                       repeats = 10)
boston_knn_3 <- train(rating~.,
                  data = train,
                  method="knn",
                  tuneLength=10,
                  trControl= trctrl_3,
                  preProcess="scale")
# refining the model
```

#### Variable Importance
```{r, include=TRUE, echo=FALSE}
### Evaluation with test set
varImp(boston_knn_3)
# In order of importance: superhost, price, neighborhood, accommodates, property type
boston_knn_3
```


```{r, include=TRUE, echo=FALSE}
boston_pred <- predict(boston_knn_3, test)
confusionMatrix(boston_pred, test$rating)
```

#### ROC Curve
```{r, echo=FALSE}
### ROC : compares predicted class to actual class
boston_eval <- (predict(boston_knn_3, newdata= test))
boston_eval_prob <- predict(boston_knn_3, newdata= test, type="prob")

boston_eval <- tibble(pred_class=boston_eval, pred_prob=boston_eval_prob$`1`, target=as.numeric(test$rating))

boston_pred <- prediction(boston_eval$pred_prob, boston_eval$target)
boston_tree_perf <- performance(boston_pred, "tpr", "fpr")

plot(boston_tree_perf, colorize=TRUE)
```

#### Log Loss
```{r, echo=FALSE}
### Log Loss : measures uncertainty of the probability predictions of the model
LogLoss(as.numeric(boston_eval$pred_prob), as.numeric(test$rating))
```

#### F1 Score
```{r, echo=FALSE}
# F1 : mean of percision and recall. want to see impact of false positive and negatives in the model
boston_pred_1 <- ifelse(boston_eval_prob$`1` < 0.5, 0, 1)

boston_eval_prob$rating <- test$rating

F1_Score(y_pred = boston_pred_1, y_true = boston_eval_prob$rating, positive = "1")
```

### KNN: Conclusions

After running the KNN model we can see that the model does not do a very good job in predicting whether or not a renter will enjoy their stay at an Airbnb in Boston. We get an accuracy of 62% which is not awful, but definitely not ideal, and should be a lot better if we are to think about implementing this model. We get a true positive rate of around 69% which is not too bad. This is saying that the actual positive class (renter enjoying their stay) will be correctly predicted 70% of the time. When put into context, if a renter could correctly predict whether or not they will enjoy their stay 70% of the time, we believe they would be happy with the result. The false positive rate on the other hand is around 50%, which is not good at all. With this percentage, a renter has a 50/50 chance of not enjoying their stay, when in fact the model predicts that they should be. As renters, we would want this percentage much lower if we were to think about renting out the place.

We can also see this tradeoff in the ROC graph. When looking at variable importance, it seems that a person's superhost status dramatically influences the model, with every other variable taking a low importance. This could be a driving factor as to why the model is not performing as well as we would have hoped, and we should look at removing this variable if we want more accurate predictions. Another metric we can look at is log loss. We get a value of -0.38, which is somewhat close to 0, so we can assume that our model has relatively low uncertainty. This can be seen as another positive attribute of the model. Finally, looking at our F1 score of 0.59 we can determine that the model could be a lot better as we are trying to get this F1 score as close to 1 as possible. The F1 interpretation being that our model has an even amount of both false positives and false negatives. 

In the future, when thinking about how to better improve this model so it is more accurate, we can use additional variables that can better predict rating. Superhost was used 100% of the time to predict the clusters, but price, neighborhood, the rest of the variables were used a very small amount, less than 35% for predicting rating. We could have also split up the rating more to account for different levels of rating, instead of just high and low.
